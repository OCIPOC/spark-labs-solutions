2.1 Shell solution
==================

---------------------------------------
Step 1: Start Spark Shell in local mode
---------------------------------------
### == scala
```bash
$   ~/apps/spark/bin/spark-shell
```

The following is in scala shell
```scala

// find all methods available on sc
// hit the TAB key
sc.[TAB key]

// print app name
sc.appName

// print magter
sc.master

// load file
val f = sc.textFile("/data/text/twinkle/sample.txt")
// result =>

// print first 3 lines
f.take(3)
// result =>

// print all data
f.collect
// result =>

// count records
f.count
// result =>

exit
```


---------------------------------------
Step 2: Start Spark Shell in distributed mode
---------------------------------------

Start  spark server if not running
```
$   ~/apps/spark/sbin/start-all.sh
```

Start shell and connect to master
```
$   ~/apps/spark/sbin/start-all.sh  --master spark://host_name:7077
```
