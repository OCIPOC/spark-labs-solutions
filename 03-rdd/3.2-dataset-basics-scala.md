# 3.2 Dataset Basics solutions

## Step 1: Start Spark Shell

```bash
  $   ~/apps/spark/bin/spark-shell
```

The following is in scala shell.  

```scala
  val f = spark.read.textFile("/data/text/twinkle/sample.txt")

  f.show

  f.collect

  val filtered = f.filter(line => line.contains("twinkle"))
  // short hand version
    val filtered = f.filter(_.contains("twinkle"))

  exit // quit shell
```


## Step 2: Large Data sets


```bash
    $   ~/apps/spark/bin/spark-shell  --executor-memory 1G  --driver-memory 1G
```



## Step 3 : Process a large file

```scala
  val f = spark.read.textFile("/data/twinkle/100M.data")

  // count lines containing the word 'diamond'
  f.filter(line => line.contains("diamond")).count()
  // res0: Long = 782519

  // count lines does NOT contain 'diamond'
  f.filter(line => !line.contains("diamond")).count()
  // res1: Long = 2347559

  // all count
  f.count()
  // res2: Long = 3130078

  // double check count
  // 782519 + 2347559
  // res3: Int = 3130078
  // res3 == res2 ... universe is safe ! :-)

  // try with larger files
  val f2 = spark.read.textFile("/data/twinkle/1G.data")
  // and repeat the above steps
```



## Step 4 : Loading multiple files

Following is typed in Scala shell

```scala

  val rdd = spark.read.textFile("/data/twinkle/*.data")  
  rdd.count()
  // res5: Long = 117534419

  // filter for 'diamond'
  val rddf = rdd.filter(line => line.contains("diamond"))

  // save
  rddf.saveAsTextFile("out1")
  exit
```



## Step 5 - Inspecting the output dir:

```bash
  $  ls -lh  out1

  # we will see 121 partitions 00000 --> 00120

  -rw-r--r--  1 sujee  staff     0B Apr  1 00:46 _SUCCESS
  -rw-r--r--  1 sujee  staff   6.2M Apr  1 00:46 part-00000
  -rw-r--r--  1 sujee  staff   6.2M Apr  1 00:46 part-00001
  -rw-r--r--  1 sujee  staff   6.2M Apr  1 00:46 part-00002
  ...
  -rw-r--r--  1 sujee  staff   6.2M Apr  1 00:46 part-00119
  -rw-r--r--  1 sujee  staff   6.2M Apr  1 00:46 part-00120
```

Inspect a file
```bash
  $   less  out1/part-00000

  like a diamond in the sky
  like a diamond in the sky
  like a diamond in the sky
  ....
```

## Bonus Lab : getting 'one' output file

```scala
  val filtered = ....
  val one = filtered.coalesce(1)
  one.saveAsTextFile("out2")
```
