Lab 3.4 : MapReduce Solutions
=============================

---------
WordCount
---------

### Scala Solution

#### Start Spark Shell
```bash
$   ~/apps/spark/bin/spark-shell
```

#### Following in Scala shell

```scala
// scala

val input = Array ("hello world", "goodbye world", "bye bye")
val r = sc.makeRDD(input)
val wordcount = r.flatMap(lines => lines.split(" ")).map(word => (word, 1)).reduceByKey(_+_)
wordcount.collect
// Array[(String, Int)] = Array((goodbye,1), (hello,1), (world,2), (bye,2))
```

#### Step 7: Large files
Follow Step 6 to generate data files
```scala
val f = sc.textFile("../data/twinkle/100M.data")
val wordcount = f.flatMap(lines => lines.split(" ")).map(word => (word, 1)).reduceByKey(_+_)
wordcount.collect
```
