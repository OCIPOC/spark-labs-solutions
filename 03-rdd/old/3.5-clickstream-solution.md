Lab 3.5 : Clickstream Analysis Solutions
========================================


---------------------
Analyzing Meetup Data
---------------------

### Scala Solution

#### Start Spark Shell

```bash
    $   ~/apps/spark/bin/spark-shell
```


#### Following in Scala shell

```scala
    // scala

    val clickstream = sc.textFile("../data/click-stream/clickstream.csv")
```

### step 5 : counting domains

```scala
    // data format:
    // timestmap, ip_address, user_id,  action,  domain,  campaign_id,  cost, session
    // 1420070400000,ip_1,user_5,clicked,facebook.com,campaign_6,139,session_98
    val domainsKV = clickstream.map{
        line => {
             val tokens = line.split(",") // split the line
             val domain = tokens(4).trim
             (domain, line) // create a KV pair (domain, record)
        }
    }
    val domainCount = domainsKV.countByKey
    //  result => scala.collection.Map[String,Long] = Map(amazon.com -> 2, funnyordie.com -> 2, nytimes.com -> 1, cnn.com -> 2, youtube.com -> 1, wikipedia.org -> 2, facebook.com -> 2, bbc.co.uk -> 1, npr.org -> 2, foxnews.com -> 3, hulu.com -> 2)
    }

    // domainCount - one liner
    clickstream.map(line => (line.split(",")(4), 1)).reduceByKey(_+_).collect
```

### step 6 :  calculating spend per domain

```scala
    // data layout:
    // timestmap, ip_address, user_id,  action,  domain,  campaign_id,  cost, session
    // 1420070400000,ip_1,user_5,clicked,facebook.com,campaign_6,139,session_98
    val domainsCosts = clickstream.map{
       line => {
             val tokens = line.split(",") // split the line
             // indexes start at zero
             val domain = tokens(4).trim
             val cost = tokens(6).trim.toInt
             (domain, cost) // create a KV pair (domain, cost)
        }
    }

    val spendPerDomain = domainsCosts.reduceByKey((a,b) => a+b)
    spendPerDomain.collect
    //  result => Array[(String, Int)] = Array((youtube.com,115), (nytimes.com,19), (npr.org,154), (cnn.com,6), (funnyordie.com,92), (facebook.com,174), (wikipedia.org,287), (foxnews.com,337), (bbc.co.uk,27), (amazon.com,84), (hulu.com,90))
```

### step 7 : find top domains

```scala
    // sort 'countByDomains' by frequency
    // sort
    domainCount.toList.sortBy{_._2}
    // result ==> List[(String, Long)] = List((nytimes.com,1), (youtube.com,1), (bbc.co.uk,1), (amazon.com,2), (funnyordie.com,2), (cnn.com,2), (wikipedia.org,2), (facebook.com,2), (npr.org,2), (hulu.com,2), (foxnews.com,3))

    // reverse
    domainCount.toList.sortBy{_._2}.reverse
    // result ==> List[(String, Long)] = List((foxnews.com,3), (hulu.com,2), (npr.org,2), (facebook.com,2), (wikipedia.org,2), (cnn.com,2), (funnyordie.com,2), (amazon.com,2), (bbc.co.uk,1), (youtube.com,1), (nytimes.com,1))


    // top domain another approach -- one liner
    // sorting by values, need to swap (k,v) --> (v,k)
    clickstream.map(line => (line.split(",")(4), 1)).reduceByKey(_+_).
          map(item => item.swap).sortByKey().collect()

    // -- bonus lab 1 : domains where users click most
    val clicksOnly =  clickstream.filter(line => line.split(",")(3) == "clicked")
    val clicksOnlydomainsKV = clicksOnly.map{
        line => {
             val tokens = line.split(",") // split the line
             val domain = tokens(4).trim
             (domain, line) // create a KV pair (domain, record)
        }
    }
    val clisksOnlyDomainCount = clicksOnlydomainsKV.countByKey
    // result ==> scala.collection.Map[String,Long] = Map(amazon.com -> 1, nytimes.com -> 1, cnn.com -> 1, youtube.com -> 1, facebook.com -> 1, npr.org -> 1, foxnews.com -> 1)
```

### bonus lab 2 : Find  view/click ratio for each domain
    // left as an exercise to reader :-)
