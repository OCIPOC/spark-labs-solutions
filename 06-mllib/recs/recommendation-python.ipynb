{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab : Classification with MLlib\n",
    "===================================\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This lab explores a well known dataset from the Czech dating website libimseti.cz.  We'll just call it the \"dating\" dataset. :)\n",
    "\n",
    "Normally we talk of users and items as different entities, but in dating websites we relate users to one another.\n",
    "\n",
    "In our example, we're going to ignore the gender and orientation of each user in doing the recommendations.   The dating dataset does include a file which identifies the gender of each participant, but for simplicity we're not handling it here. This isn't as bad as it sounds, as most users likely will rate only one gender of dating site participants, and will no doubt receive recommendations from the same gender. Naturally there are always exceptions.\n",
    "\n",
    "The checked in version is a tiny subset of the actual, as only the first 9999 users are included.  Furthermore, the ratings outside the subset are ignored, so a good portion of users have no data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Spark...\n",
      "Spark found in :  /home/ubuntu/spark\n",
      "Spark config:\n",
      "\t executor.memory=2g\n",
      "\tsome_property=some_value\n",
      "\tspark.app.name=TestApp\n",
      "\tspark.master=local[*]\n",
      "\tspark.sql.warehouse.dir=/tmp/tmpyam46jj0\n",
      "\tspark.submit.deployMode=client\n",
      "\tspark.ui.showConsoleProgress=true\n",
      "Spark UI running on port 4042\n"
     ]
    }
   ],
   "source": [
    "# initialize Spark Session\n",
    "import os\n",
    "import sys\n",
    "top_dir = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "if top_dir not in sys.path:\n",
    "    sys.path.append(top_dir)\n",
    "\n",
    "from init_spark import init_spark\n",
    "spark = init_spark()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Inspect Data\n",
    "* Sample Data : [/data/dating/sample.txt](/data/dating/sample.txt)\n",
    "* Rating data file : [/data/dating/medium/ratings.dat](/data/dating/medium/ratings.dat)\n",
    "\n",
    "(browsers may not display the data properly, open the data in text editor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Create Rating Object for the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.textFile(\"../data/dating/medium/ratings.dat\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the dating website \n",
    "* Users = Users\n",
    "* Products = Other users\n",
    "* Rating = Rating given by one user to anothr user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_data = data.map(lambda x : x.split(\",\"))\n",
    "#  Rating represents a (user, product, rating) tuple.\n",
    "ratings = splitted_data.map(lambda x : Rating(x[0],x[1],x[2]))\n",
    "# ratings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ALS.train(ratings, rank = 10, iterations = 5, lambda_= 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Transform the Rating object to a tuple of User, Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of rating to test model's effectiveness\n",
    "# TODO: TRANSFORM Rating -> Tuple of (user, product)\n",
    "# (i.e., get rid of the rating)\n",
    "userItems = ratings.map(lambda x: (int(x[0]),int(x[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Use the predictAll method to map the output to User, Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a test prediction\n",
    "# TODO call model.predictAll() on userItems, and then map the output of that \n",
    "# to (user, product), rating\n",
    "predict = model.predictAll(userItems)\n",
    "recs = predict.map(lambda x: ((int(x[0]), int(x[1])), int(x[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsAndRecs = ratings.map(lambda x: ((int(x[0]), int(x[1])), int(x[2]))).join(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = ratingsAndRecs.map(lambda x: (x[1][0] - x[1][1]) * (x[1][0] - x[1][1])).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2576640412262527\n"
     ]
    }
   ],
   "source": [
    "print (mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 : Find recommendations for Users based on ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommendProductsForUsers will give recommendations for all users in an arrray\n",
    "# Number of recommendations needed should be provided as arguments\n",
    "recsForEachUser = model.recommendProductsForUsers(3)\n",
    "recsForEachUser.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rating(user=4, product=5702, rating=53.855695075320156), Rating(user=4, product=2928, rating=45.60359291212251), Rating(user=4, product=9967, rating=42.06318720908149), Rating(user=4, product=6807, rating=40.755852549595176), Rating(user=4, product=484, rating=40.75157465417058), Rating(user=4, product=1642, rating=39.33000008350386), Rating(user=4, product=4901, rating=38.75331923891722), Rating(user=4, product=9018, rating=37.487033262569184), Rating(user=4, product=8855, rating=37.32644276225213), Rating(user=4, product=2853, rating=37.2282182227778)]\n"
     ]
    }
   ],
   "source": [
    "# recommendProducts will give recommendations for the particular user\n",
    "# parameters : (User, NumberOfRecommemdationsNeeded\n",
    "# recsForEachUser = model.recommendProducts(892, 4)\n",
    "recsForEachUser = model.recommendProducts(4, 10)\n",
    "print (recsForEachUser)\n",
    "\n",
    "# Beware: some numbers aren't represented (e.g. 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Running on some of your own data\n",
    "\n",
    "Create a file called personalratings.txt.  Include some test data as preferences.\n",
    "We have included a file /data/dating/sample.txt for you.\n",
    "you can refer to it.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6453752232600356\n",
      "[Rating(user=4, product=4901, rating=41.33717392078803), Rating(user=4, product=2571, rating=39.86126854301914), Rating(user=4, product=4354, rating=38.32360994639145)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Rating(user=4, product=4901, rating=41.33717392078803),\n",
       " Rating(user=4, product=2571, rating=39.86126854301914)]"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personaldata = sc.textFile(\"personalratings.txt\")\n",
    "\n",
    "# And create the solution like you did using ratings.dat file\n",
    "splitted_data = data.map(lambda x : x.split(\",\"))\n",
    "ratings = splitted_data.map(lambda x : Rating(x[0],x[1],x[2]))\n",
    "model = ALS.train(ratings, rank = 10, iterations = 5, lambda_= 0.01)\n",
    "userItems = ratings.map(lambda x: (int(x[0]),int(x[1])))\n",
    "predict = model.predictAll(userItems)\n",
    "recs = predict.map(lambda x: ((int(x[0]), int(x[1])), int(x[2])))\n",
    "ratingsAndRecs = ratings.map(lambda x: ((int(x[0]), int(x[1])), int(x[2]))).join(recs)\n",
    "mse = ratingsAndRecs.map(lambda x: (x[1][0] - x[1][1]) * (x[1][0] - x[1][1])).mean()\n",
    "print (mse)\n",
    "recsForEachUser = model.recommendProductsForUsers(4)\n",
    "recsForEachUser = model.recommendProducts(4, 3)\n",
    "print (recsForEachUser)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
