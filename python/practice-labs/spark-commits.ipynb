{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Commits Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Spark...\n",
      "Spark found in :  /home/ubuntu/dev/spark\n",
      "Spark config:\n",
      "\t executor.memory=2g\n",
      "\tsome_property=some_value\n",
      "\tspark.app.name=TestApp\n",
      "\tspark.master=local[*]\n",
      "\tspark.sql.warehouse.dir=/tmp/tmpctke06vv\n",
      "\tspark.submit.deployMode=client\n",
      "\tspark.ui.showConsoleProgress=true\n",
      "Spark UI running on port 4041\n"
     ]
    }
   ],
   "source": [
    "# initialize Spark Session\n",
    "import os\n",
    "import sys\n",
    "top_dir = os.path.abspath(os.path.join(os.getcwd(), \"../\"))\n",
    "if top_dir not in sys.path:\n",
    "    sys.path.append(top_dir)\n",
    "\n",
    "from init_spark import init_spark\n",
    "spark = init_spark()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "commits = spark.read. \\\n",
    "              option(\"header\", \"true\"). \\\n",
    "              option(\"delimiter\", \"|\"). \\\n",
    "              csv(\"/data/spark-commits/spark-commits.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sha: string (nullable = true)\n",
      " |-- committer: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- comment: string (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                 sha|           committer|               email|                date|             comment|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|68f2142cfd2ca632a...|        Dilip Biswal|  dbiswal@us.ibm.com|Sat Feb 25 23:56:...|[SQL] Duplicate t...|\n",
      "|89608cf26226e28f3...|         Wenchen Fan|wenchen@databrick...|Sat Feb 25 23:01:...|[SPARK-17075][SQL...|\n",
      "|6ab60542e8e803b1d...|   Joseph K. Bradley|joseph@databricks...|Sat Feb 25 22:24:...|[MINOR][ML][DOC] ...|\n",
      "|410392ed75da64c69...|           Devaraj K|  devaraj@apache.org|Sat Feb 25 21:48:...|[SPARK-15288][MES...|\n",
      "|fe07de9566b345c7a...|             lvdongr|lv.dongdong@zte.c...|Sat Feb 25 21:47:...|[SPARK-19673][SQL...|\n",
      "|061bcfb869fe5f64e...|          Boaz Mohar| boazmohar@gmail.com|Sat Feb 25 11:32:...|[MINOR][DOCS] Fix...|\n",
      "|8f0511ed49a353fb0...|   Herman van Hovell|hvanhovell@databr...|Fri Feb 24 23:05:...|[SPARK-19650] Com...|\n",
      "|4cb025afafe63d587...|             Xiao Li|gatorsmile@gmail.com|Fri Feb 24 23:03:...|[SPARK-19735][SQL...|\n",
      "|1b9ba258e086e2ba8...|Ramkumar Venkatar...|rvenkataraman@pay...|Sat Feb 25 02:18:...|[MINOR][DOCS] Fix...|\n",
      "|fa7c582e9442b985a...|      Shubham Chopra|schopra31@bloombe...|Fri Feb 24 15:40:...|[SPARK-15355][COR...|\n",
      "|330c3e33bd10f035f...|          Jeff Zhang|   zjffdu@apache.org|Fri Feb 24 15:04:...|[SPARK-13330][PYS...|\n",
      "|5f74148bb45912b9f...|        Imran Rashid|irashid@cloudera.com|Fri Feb 24 13:03:...|[SPARK-19597][COR...|\n",
      "|5cbd3b59ba6735c59...|      Kay Ousterhout|kayousterhout@gma...|Fri Feb 24 11:42:...|[SPARK-19560] Imp...|\n",
      "|69d0da6373979ce5b...|         wangzhenhua|wangzhenhua@huawe...|Fri Feb 24 10:24:...|[SPARK-17078][SQL...|\n",
      "|05954f32e9bde56dc...|           Shuai Lin|linshuai2012@gmai...|Fri Feb 24 10:24:...|[SPARK-17075][SQL...|\n",
      "|3e40f6c3d6fc0bcd8...|         Tejas Patil|       tejasp@fb.com|Fri Feb 24 09:46:...|[SPARK-17495][SQL...|\n",
      "|a920a4369434c8427...|           jerryshao|sshao@hortonworks...|Fri Feb 24 09:31:...|[SPARK-19038][YAR...|\n",
      "|b0a8c16fecd4337f7...|           jerryshao|sshao@hortonworks...|Fri Feb 24 09:28:...|[SPARK-19707][COR...|\n",
      "|4a5e38f5747148022...|             zero323|zero323@users.nor...|Fri Feb 24 08:22:...|[SPARK-19161][PYT...|\n",
      "|8f33731e796750e6f...|           windpiger| songjun@outlook.com|Thu Feb 23 22:57:...|[SPARK-19664][SQL...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "commits.printSchema()\n",
    "commits.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                 sha|           committer|               email|                date|             comment|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|68f2142cfd2ca632a...|        Dilip Biswal|  dbiswal@us.ibm.com|Sat Feb 25 23:56:...|[SQL] Duplicate t...|\n",
      "|89608cf26226e28f3...|         Wenchen Fan|wenchen@databrick...|Sat Feb 25 23:01:...|[SPARK-17075][SQL...|\n",
      "|6ab60542e8e803b1d...|   Joseph K. Bradley|joseph@databricks...|Sat Feb 25 22:24:...|[MINOR][ML][DOC] ...|\n",
      "|410392ed75da64c69...|           Devaraj K|  devaraj@apache.org|Sat Feb 25 21:48:...|[SPARK-15288][MES...|\n",
      "|fe07de9566b345c7a...|             lvdongr|lv.dongdong@zte.c...|Sat Feb 25 21:47:...|[SPARK-19673][SQL...|\n",
      "|061bcfb869fe5f64e...|          Boaz Mohar| boazmohar@gmail.com|Sat Feb 25 11:32:...|[MINOR][DOCS] Fix...|\n",
      "|8f0511ed49a353fb0...|   Herman van Hovell|hvanhovell@databr...|Fri Feb 24 23:05:...|[SPARK-19650] Com...|\n",
      "|4cb025afafe63d587...|             Xiao Li|gatorsmile@gmail.com|Fri Feb 24 23:03:...|[SPARK-19735][SQL...|\n",
      "|1b9ba258e086e2ba8...|Ramkumar Venkatar...|rvenkataraman@pay...|Sat Feb 25 02:18:...|[MINOR][DOCS] Fix...|\n",
      "|fa7c582e9442b985a...|      Shubham Chopra|schopra31@bloombe...|Fri Feb 24 15:40:...|[SPARK-15355][COR...|\n",
      "|330c3e33bd10f035f...|          Jeff Zhang|   zjffdu@apache.org|Fri Feb 24 15:04:...|[SPARK-13330][PYS...|\n",
      "|5f74148bb45912b9f...|        Imran Rashid|irashid@cloudera.com|Fri Feb 24 13:03:...|[SPARK-19597][COR...|\n",
      "|5cbd3b59ba6735c59...|      Kay Ousterhout|kayousterhout@gma...|Fri Feb 24 11:42:...|[SPARK-19560] Imp...|\n",
      "|69d0da6373979ce5b...|         wangzhenhua|wangzhenhua@huawe...|Fri Feb 24 10:24:...|[SPARK-17078][SQL...|\n",
      "|05954f32e9bde56dc...|           Shuai Lin|linshuai2012@gmai...|Fri Feb 24 10:24:...|[SPARK-17075][SQL...|\n",
      "|3e40f6c3d6fc0bcd8...|         Tejas Patil|       tejasp@fb.com|Fri Feb 24 09:46:...|[SPARK-17495][SQL...|\n",
      "|a920a4369434c8427...|           jerryshao|sshao@hortonworks...|Fri Feb 24 09:31:...|[SPARK-19038][YAR...|\n",
      "|b0a8c16fecd4337f7...|           jerryshao|sshao@hortonworks...|Fri Feb 24 09:28:...|[SPARK-19707][COR...|\n",
      "|4a5e38f5747148022...|             zero323|zero323@users.nor...|Fri Feb 24 08:22:...|[SPARK-19161][PYT...|\n",
      "|8f33731e796750e6f...|           windpiger| songjun@outlook.com|Thu Feb 23 22:57:...|[SPARK-19664][SQL...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# setup a sql table\n",
    "commits.createOrReplaceTempView(\"commits\")\n",
    "\n",
    "spark.sql(\"select * from commits\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    4116|\n",
      "+--------+\n",
      "\n",
      "+--------------------+-----------------+--------------------+--------------------+--------------------+\n",
      "|                 sha|        committer|               email|                date|             comment|\n",
      "+--------------------+-----------------+--------------------+--------------------+--------------------+\n",
      "|89608cf26226e28f3...|      Wenchen Fan|wenchen@databrick...|Sat Feb 25 23:01:...|[SPARK-17075][SQL...|\n",
      "|6ab60542e8e803b1d...|Joseph K. Bradley|joseph@databricks...|Sat Feb 25 22:24:...|[MINOR][ML][DOC] ...|\n",
      "|8f0511ed49a353fb0...|Herman van Hovell|hvanhovell@databr...|Fri Feb 24 23:05:...|[SPARK-19650] Com...|\n",
      "|4fa4cf1d4ce51ce61...|      Wenchen Fan|wenchen@databrick...|Thu Feb 23 13:22:...|[SPARK-19706][PYS...|\n",
      "|9bf4e2baad0e2851d...|     Shixiong Zhu|shixiong@databric...|Thu Feb 23 11:25:...|[SPARK-19497][SS]...|\n",
      "|78eae7e67fd5dec0c...|Herman van Hovell|hvanhovell@databr...|Thu Feb 23 10:25:...|[SPARK-19459] Sup...|\n",
      "|10c566cc3b5f93ddd...|  Bogdan Raducanu|bogdan@databricks...|Wed Feb 22 15:42:...|[SPARK-13721][SQL...|\n",
      "|0733a54a4517b8229...|      Reynold Xin| rxin@databricks.com|Mon Feb 20 12:21:...|[SPARK-19669][SQL...|\n",
      "|776b8f17cfc687a57...|      Wenchen Fan|wenchen@databrick...|Sun Feb 19 18:13:...|[SPARK-19563][SQL...|\n",
      "|b486ffc86d8ad6c30...|     Ala Luszczak|  ala@databricks.com|Sat Feb 18 07:51:...|[SPARK-19447] Mak...|\n",
      "|15b144d2bf4555981...|     Shixiong Zhu|shixiong@databric...|Fri Feb 17 19:04:...|[SPARK-19617][SS]...|\n",
      "|3d0c3af0a76757c20...|       Davies Liu|davies@databricks...|Fri Feb 17 09:38:...|[SPARK-19500] [SQ...|\n",
      "|54d23599df7c28a76...|      Wenchen Fan|wenchen@databrick...|Thu Feb 16 21:09:...|[SPARK-18120][SPA...|\n",
      "|fc02ef95cdfc22660...|     Shixiong Zhu|shixiong@databric...|Wed Feb 15 20:51:...|[SPARK-19603][SS]...|\n",
      "|21b4ba2d6f21a9759...|     Shixiong Zhu|shixiong@databric...|Wed Feb 15 16:21:...|[SPARK-19599][SS]...|\n",
      "|f6c3bba22501ee775...|         Yin Huai|yhuai@databricks.com|Wed Feb 15 14:41:...|[SPARK-19604][TES...|\n",
      "|8b75f8c1c9acae9c5...|      Wenchen Fan|wenchen@databrick...|Wed Feb 15 08:15:...|[SPARK-19587][SQL...|\n",
      "|733c59ec1ee5746c3...|      Reynold Xin| rxin@databricks.com|Wed Feb 15 17:10:...|[SPARK-16475][SQL...|\n",
      "|b55563c17ec67f560...|     Ala Luszczak|  ala@databricks.com|Wed Feb 15 17:06:...|[SPARK-19607] Fin...|\n",
      "|da7aef7a0ea921a2d...|      Reynold Xin| rxin@databricks.com|Tue Feb 14 14:11:...|[SPARK-16475][SQL...|\n",
      "+--------------------+-----------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#find commits from databricks.com\n",
    "spark.sql(\"select count(*) from commits where email like '%databricks.com'\").show()\n",
    "spark.sql(\"select * from commits where email like '%databricks.com'\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+-----+\n",
      "|email                      |total|\n",
      "+---------------------------+-----+\n",
      "|matei@eecs.berkeley.edu    |1341 |\n",
      "|pwendell@gmail.com         |791  |\n",
      "|rxin@databricks.com        |700  |\n",
      "|tathagata.das1565@gmail.com|502  |\n",
      "|rxin@apache.org            |430  |\n",
      "|davies@databricks.com      |389  |\n",
      "|meng@databricks.com        |338  |\n",
      "|sowen@cloudera.com         |332  |\n",
      "|joshrosen@databricks.com   |311  |\n",
      "|wenchen@databricks.com     |282  |\n",
      "+---------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find top committers\n",
    "\n",
    "s = \"\"\"\n",
    "select email, count(*) as total  \n",
    "from commits \n",
    "group by email \n",
    "order by total desc \n",
    "limit 10\n",
    "\"\"\"\n",
    "spark.sql(s).show(n=10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
