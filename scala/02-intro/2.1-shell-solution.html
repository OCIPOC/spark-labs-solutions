<h1 id="shell-solution">2.1 Shell solution</h1>
<table>
<tbody>
<tr class="odd">
<td>Step 1: Start Spark Shell in local mode</td>
</tr>
</tbody>
</table>
<h3 id="scala">== scala</h3>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb1-1" data-line-number="1">$   <span class="ex">~/spark/bin/spark-shell</span></a></code></pre></div>
<p>The following is in scala shell</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode scala"><code class="sourceCode scala"><a class="sourceLine" id="cb2-1" data-line-number="1"></a>
<a class="sourceLine" id="cb2-2" data-line-number="2"><span class="co">// find all methods available on sc</span></a>
<a class="sourceLine" id="cb2-3" data-line-number="3"><span class="co">// hit the TAB key</span></a>
<a class="sourceLine" id="cb2-4" data-line-number="4">sc.[TAB key]</a>
<a class="sourceLine" id="cb2-5" data-line-number="5"></a>
<a class="sourceLine" id="cb2-6" data-line-number="6"><span class="co">// print app name</span></a>
<a class="sourceLine" id="cb2-7" data-line-number="7">sc.<span class="fu">appName</span></a>
<a class="sourceLine" id="cb2-8" data-line-number="8"></a>
<a class="sourceLine" id="cb2-9" data-line-number="9"><span class="co">// print magter</span></a>
<a class="sourceLine" id="cb2-10" data-line-number="10">sc.<span class="fu">master</span></a>
<a class="sourceLine" id="cb2-11" data-line-number="11"></a>
<a class="sourceLine" id="cb2-12" data-line-number="12"><span class="co">// load file</span></a>
<a class="sourceLine" id="cb2-13" data-line-number="13"><span class="kw">val</span> f = sc.<span class="fu">textFile</span>(<span class="st">&quot;/data/text/twinkle/sample.txt&quot;</span>)</a>
<a class="sourceLine" id="cb2-14" data-line-number="14"><span class="co">// result =&gt;</span></a>
<a class="sourceLine" id="cb2-15" data-line-number="15"></a>
<a class="sourceLine" id="cb2-16" data-line-number="16"><span class="co">// print first 3 lines</span></a>
<a class="sourceLine" id="cb2-17" data-line-number="17">f.<span class="fu">take</span>(<span class="dv">3</span>)</a>
<a class="sourceLine" id="cb2-18" data-line-number="18"><span class="co">// result =&gt;</span></a>
<a class="sourceLine" id="cb2-19" data-line-number="19"></a>
<a class="sourceLine" id="cb2-20" data-line-number="20"><span class="co">// print all data</span></a>
<a class="sourceLine" id="cb2-21" data-line-number="21">f.<span class="fu">collect</span></a>
<a class="sourceLine" id="cb2-22" data-line-number="22"><span class="co">// result =&gt;</span></a>
<a class="sourceLine" id="cb2-23" data-line-number="23"></a>
<a class="sourceLine" id="cb2-24" data-line-number="24"><span class="co">// count records</span></a>
<a class="sourceLine" id="cb2-25" data-line-number="25">f.<span class="fu">count</span></a>
<a class="sourceLine" id="cb2-26" data-line-number="26"><span class="co">// result =&gt;</span></a>
<a class="sourceLine" id="cb2-27" data-line-number="27"></a>
<a class="sourceLine" id="cb2-28" data-line-number="28">exit</a></code></pre></div>
<table>
<tbody>
<tr class="odd">
<td>Step 2: Start Spark Shell in distributed mode</td>
</tr>
</tbody>
</table>
<p>Start spark server if not running</p>
<pre><code>$   ~/spark/sbin/start-all.sh</code></pre>
<p>Start shell and connect to master</p>
<pre><code>$   ~/spark/sbin/start-all.sh  --master spark://host_name:7077</code></pre>
