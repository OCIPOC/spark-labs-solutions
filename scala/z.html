<p><a href="../README.md">&lt;&lt; back to main index</a> / <a href="./README.md">API labs</a></p>
<h1 id="lab-5.1-first-spark-job-submission">Lab 5.1 First Spark Job Submission</h1>
<h3 id="overview">Overview</h3>
<p>Submit a job for Spark</p>
<h3 id="depends-on">Depends On</h3>
<p>None</p>
<h3 id="run-time">Run time</h3>
<p>20-30 mins</p>
<table>
<tbody>
<tr class="odd">
<td>STEP 1: Edit source file</td>
</tr>
</tbody>
</table>
<p>Go to the project root directory</p>
<pre><code>$    cd ~/spark-labs/data/text/twinkle</code></pre>
<p><strong>edit file : <code>src/main/scala/x/ProcessFiles.scala</code></strong><br />
<strong>And fix the TODO items</strong></p>
<pre><code>$    vi  src/main/scala/x/ProcessFiles.scala
# or
$    nano  src/main/scala/x/ProcessFiles.scala</code></pre>
<table>
<tbody>
<tr class="odd">
<td>STEP 2: Start Spark Server / Shell</td>
</tr>
</tbody>
</table>
<pre><code>$  ~/spark/sbin/start-all.sh</code></pre>
<p>Starting Shell (with 4G memory)</p>
<h4 id="scala">== Scala</h4>
<pre><code>$  ~/spark/bin/spark-shell  --master &lt;spark master uri&gt;  --executor-memory 4G</code></pre>
<h4 id="python">== Python:</h4>
<pre><code>$   ~/spark/bin/pyspark   --master  spark-server-uri
#                                         ^^^^^^^^^^^^^^^^
#                                    update this to match your spark server

$   ~/spark/bin/pyspark   --master  spark://localhost:7077</code></pre>
<table style="width:24%;">
<colgroup>
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="header">
<th>STEP 3: Load RDD</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Load a big file (e.g 500M.data)</td>
</tr>
<tr class="even">
<td><code>scala // scala val f = sc.textFile(&quot;/data/twinkle/500M.data&quot;)</code></td>
</tr>
<tr class="odd">
<td><code>python # python f = sc.textFile(&quot;/data/twinkle/500M.data&quot;)</code></td>
</tr>
<tr class="even">
<td><strong>count the number of lines in this file</strong> Hint : <code>count()</code></td>
</tr>
<tr class="odd">
<td><strong>Notice the time took</strong> <strong>Do the same count() operation a few times until the execution time ‘stablizes’</strong> <strong>Can you explain the behavior of count() execution time ?</strong></td>
</tr>
</tbody>
</table>
<h2 id="step-4-cache">STEP 4: Cache</h2>
<p><strong>cache the file using <code>cache()</code> action.</strong></p>
<pre><code>f.cache()</code></pre>
<p><strong>Run the <code>count()</code> again. Notice the time. Can you explain this behavior ? :-)</strong></p>
<p><strong>Run count() a few more times and note the execution times.</strong><br />
<strong>Do the timings make sense?</strong></p>
<table style="width:51%;">
<colgroup>
<col style="width: 51%" />
</colgroup>
<thead>
<tr class="header">
<th>STEP 5: Understanding Cache storage</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Go to spark shell UI @ port 4040 <strong>Inspect ‘storage’ tab</strong></td>
</tr>
<tr class="even">
<td><img src="../images/3.4.png" alt="caching" /></td>
</tr>
<tr class="odd">
<td><strong>Can you see the cached RDD? What is the memory size?</strong> <strong>What are the implications?</strong></td>
</tr>
</tbody>
</table>
<h2 id="step-5-cache-a-larger-file">STEP 5: Cache a larger file</h2>
<p><strong>Try to cache 1G.data file and do count()</strong><br />
Is caching successful ? If not, try starting Spark shell with more memory</p>
<table style="width:49%;">
<colgroup>
<col style="width: 48%" />
</colgroup>
<thead>
<tr class="header">
<th>Step 6 : Reducing memory footprint</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>There are various levels of memory caching. Here are a couple: * Raw caching (<code>rdd.persist(org.apache.spark.storage.StorageLevel.MEMORY_ONLY)</code>) * Serialized Caching (<code>rdd.persist(org.apache.spark.storage.StorageLevel.MEMORY_ONLY_SER)</code>)</td>
</tr>
<tr class="even">
<td><strong>Try both options <code>f.persist(....)</code> . Monitor memory consumption in storage tab</strong></td>
</tr>
</tbody>
</table>
<h2 id="group-discussion">Group discussion</h2>
<ul>
<li>mechanics of caching</li>
<li>implications of caching vs memory</li>
</ul>
<table>
<tbody>
<tr class="odd">
<td>BONUS LAB: Caching data from Amazon S3</td>
</tr>
</tbody>
</table>
<p>We have some data files stored in Amazon S3. Here are couple of path names * s3n://elephantscale-public/data/text/twinkle/100M.data * s3n://elephantscale-public/data/text/twinkle/500M.data * …</p>
<p>Try loading these files. Measure performance time before and after caching.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode scala"><code class="sourceCode scala"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="co">// scala</span></a>
<a class="sourceLine" id="cb7-2" data-line-number="2"><span class="kw">val</span> f = sc.<span class="fu">textFile</span>(<span class="st">&quot;s3n://....file location&quot;</span>)</a>
<a class="sourceLine" id="cb7-3" data-line-number="3">f.<span class="fu">count</span>() <span class="co">// measure time.. do it a couple of times</span></a>
<a class="sourceLine" id="cb7-4" data-line-number="4">f.<span class="fu">cache</span>()</a>
<a class="sourceLine" id="cb7-5" data-line-number="5">f.<span class="fu">count</span>() <span class="co">// measure time.. do it a couple of times</span></a></code></pre></div>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb8-1" data-line-number="1"><span class="op">//</span> scala</a>
<a class="sourceLine" id="cb8-2" data-line-number="2">f <span class="op">=</span> sc.textFile(<span class="st">&quot;s3n://....file location&quot;</span>)</a>
<a class="sourceLine" id="cb8-3" data-line-number="3">f.count() <span class="op">//</span> measure time.. do it a couple of times</a>
<a class="sourceLine" id="cb8-4" data-line-number="4">f.cache()</a>
<a class="sourceLine" id="cb8-5" data-line-number="5">f.count() <span class="op">//</span> measure time.. do it a couple of times</a></code></pre></div>
<table>
<tbody>
<tr class="odd">
<td>Further Reading</td>
</tr>
</tbody>
</table>
<ul>
<li><a href="http://sujee.net/2015/01/22/understanding-spark-caching/">Understanding Spark Caching by Sujee Maniyam</a></li>
</ul>
